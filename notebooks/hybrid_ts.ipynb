{
 "cells": [
  {
   "cell_type": "code",
   "id": "fd619951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T17:36:22.873887Z",
     "start_time": "2026-02-22T17:36:22.832351Z"
    }
   },
   "source": [
    "import pathlib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change to the project root directory\n",
    "project_root = pathlib.Path(\"/Users/victormp/Desktop/ml/ml-project\")\n",
    "os.chdir(project_root)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from darts.models import ARIMA\n",
    "from darts import TimeSeries\n",
    "from darts import concatenate\n",
    "from darts.metrics import mse as MSE\n",
    "from darts.metrics import mae as MAE\n",
    "from darts.models import SKLearnModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.train import Trainer\n",
    "from src.train import CrossValidator\n",
    "from src.train import DartsBridge\n",
    "from src.models import Classic_TCN\n",
    "from src.models import AdditiveHybrid_ARMA_TCN\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "a8612442",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "be3ece07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T17:36:25.179529Z",
     "start_time": "2026-02-22T17:36:25.104725Z"
    }
   },
   "source": [
    "data_path = pathlib.Path(\"data/DCOILWTICO.csv\")\n",
    "print(f\"Loading from: {data_path.absolute()}\")\n",
    "print(f\"File exists: {data_path.exists()}\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "data.rename(columns = {\"observation_date\" : \"date\", \"DCOILWTICO\" : \"price\"}, inplace  = True)\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data = data.set_index(\"date\")\n",
    "data[\"return\"] = np.log(data[\"price\"]) - np.log(data[\"price\"].shift(1))\n",
    "returns = data[\"return\"].replace([np.inf, -np.inf], np.nan).dropna().astype(\"float32\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: /Users/victormp/Desktop/ml/ml-project/data/DCOILWTICO.csv\n",
      "File exists: True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "d7559ca5",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "52ff221a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T17:36:27.122429Z",
     "start_time": "2026-02-22T17:36:27.088235Z"
    }
   },
   "source": [
    "# Three-way split: 60% train, 20% validation, 20% test\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_end = int(len(returns) * train_ratio)\n",
    "val_end = int(len(returns) * (train_ratio + val_ratio))\n",
    "\n",
    "# Split the data\n",
    "y_train = returns.iloc[:train_end]\n",
    "y_val = returns.iloc[train_end:val_end]\n",
    "y_test = returns.iloc[val_end:]\n",
    "\n",
    "# Convert to darts TimeSeries objects\n",
    "train_series = TimeSeries.from_values(y_train)\n",
    "val_series = TimeSeries.from_values(y_val)\n",
    "test_series = TimeSeries.from_values(y_test)\n",
    "\n",
    "print(f\"Train size: {len(train_series)} ({train_ratio*100}%)\")\n",
    "print(f\"Validation size: {len(val_series)} ({val_ratio*100}%)\")\n",
    "print(f\"Test size: {len(test_series)} ({(1-train_ratio-val_ratio)*100}%)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 715 (60.0%)\n",
      "Validation size: 239 (20.0%)\n",
      "Test size: 239 (20.0%)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "8b8bd761",
   "metadata": {},
   "source": [
    "# Train AR Model\n",
    "### Calculate residuals, preditions on training set, and the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6aa314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from weights/model_weights_ar1.pkl\n",
      "============================================================\n",
      "Fitting AR(1) Model\n",
      "============================================================\n",
      "AR(1) MSE on training data: 0.000593\n",
      "AR(1) MAE on training data: 0.018579\n",
      "\n",
      "Loaded model weights from weights/model_weights_ar5.pkl\n",
      "============================================================\n",
      "Fitting AR(5) Model\n",
      "============================================================\n",
      "AR(5) MSE on training data: 0.000593\n",
      "AR(5) MAE on training data: 0.018581\n",
      "\n",
      "============================================================\n",
      " AR(1) available in ar_results[1]['model']\n",
      " AR(5) available in ar_results[5]['model']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#Flexible AR model\n",
    "AR_ORDERS = [1, 5]\n",
    "\n",
    "# Dictionary to store results\n",
    "ar_results = {}\n",
    "\n",
    "\n",
    "for ar_order in AR_ORDERS:\n",
    "\n",
    "    if os.path.exists(f\"weights/model_weights_ar{ar_order}.pkl\"):\n",
    "        with open(f\"weights/model_weights_ar{ar_order}.pkl\", \"rb\") as f:\n",
    "            model = ARIMA.load(f)\n",
    "            print(f\"Loaded model weights from weights/model_weights_ar{ar_order}.pkl\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"Fitting AR({ar_order}) Model\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        model.fit(train_series)\n",
    "        residuals = model.residuals(train_series)\n",
    "        train_series_predict = model.predict(len(train_series))\n",
    "\n",
    "        # To avoid nan, only compute MSE on pairs where both are not nan\n",
    "        pred_vals = train_series_predict.values().flatten()\n",
    "        true_vals = train_series.values().flatten()\n",
    "\n",
    "        # Remove pairs where either is nan\n",
    "        mask = ~np.isnan(pred_vals) & ~np.isnan(true_vals)\n",
    "        mse = np.mean((true_vals[mask] - pred_vals[mask]) ** 2)\n",
    "        mae = np.mean(np.absolute(true_vals[mask] - pred_vals[mask]))\n",
    "\n",
    "        print(f\"AR({ar_order}) MSE on training data: {mse:.6f}\")\n",
    "        print(f\"AR({ar_order}) MAE on training data: {mae:.6f}\")\n",
    "\n",
    "        # Store results for later use\n",
    "        ar_results[ar_order] = {\n",
    "            'model': model,\n",
    "            'residuals': residuals,\n",
    "            'predictions': train_series_predict,\n",
    "            'mse': mse, \n",
    "            'mae': mae, \n",
    "        }\n",
    "        print()\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(f\"Model_weights_ar{ar_order}.pkl does not exist.\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Fitting AR({ar_order}) Model\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Train model and calculate residuals, compute MSE\n",
    "        model = ARIMA(p=ar_order, d=0, q=0)\n",
    "        model.fit(train_series)\n",
    "        model.save(f'weights/model_weights_ar{ar_order}.pkl')\n",
    "        residuals = model.residuals(train_series)\n",
    "        train_series_predict = model.predict(len(train_series))\n",
    "\n",
    "        # To avoid nan, only compute MSE on pairs where both are not nan\n",
    "        pred_vals = train_series_predict.values().flatten()\n",
    "        true_vals = train_series.values().flatten()\n",
    "\n",
    "        # Remove pairs where either is nan\n",
    "        mask = ~np.isnan(pred_vals) & ~np.isnan(true_vals)\n",
    "        mse = np.mean((true_vals[mask] - pred_vals[mask]) ** 2)\n",
    "        mae = np.mean(np.absolute(true_vals[mask] - pred_vals[mask]))\n",
    "\n",
    "        print(f\"AR({ar_order}) MSE on training data: {mse:.6f}\")\n",
    "        print(f\"AR({ar_order}) MAE on training data: {mae:.6f}\")\n",
    "\n",
    "        # Store results for later use\n",
    "        ar_results[ar_order] = {\n",
    "            'model': model,\n",
    "            'residuals': residuals,\n",
    "            'predictions': train_series_predict,\n",
    "            'mse': mse, \n",
    "            'mae': mae, \n",
    "        }\n",
    "        print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "for ar_order in AR_ORDERS:\n",
    "    print(f\" AR({ar_order}) available in ar_results[{ar_order}]['model']\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3d7a1",
   "metadata": {},
   "source": [
    "# Train TCN"
   ]
  },
  {
   "cell_type": "code",
   "id": "5012343e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T17:00:50.328066Z",
     "start_time": "2026-02-22T17:00:37.662104Z"
    }
   },
   "source": [
    "#define hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'kernel_size': [2, 3, 5],\n",
    "    'num_filters': [64, 128],\n",
    "    'num_layers': [3, 5, 7],\n",
    "    'dilation_base': [2, 4],\n",
    "    'lr': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "#run cross-validation\n",
    "cv = CrossValidator(\n",
    "    model_type=\"classic\",\n",
    "    hyperparameter_grid=hyperparameter_grid,\n",
    "    num_epochs=100,\n",
    "    seed=42\n",
    ")\n",
    "cv.fit(train_series, val_series)\n",
    "best_config_tcn = cv.get_best_config()\n",
    "results_tcn_df = cv.get_results()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Epoch [20/100], Training Loss: 0.017914\n",
      "Epoch [40/100], Training Loss: 0.004131\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.004677\n",
      "   MAE:  0.065979\n",
      "   RMSE: 0.068388\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.007943\n",
      "   MAE:  0.087334\n",
      "   RMSE: 0.089123\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000424\n",
      "   MAE:  0.016755\n",
      "   RMSE: 0.020582\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Epoch [20/100], Training Loss: 0.017914\n",
      "Epoch [40/100], Training Loss: 0.004131\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.004677\n",
      "   MAE:  0.065979\n",
      "   RMSE: 0.068388\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.007943\n",
      "   MAE:  0.087334\n",
      "   RMSE: 0.089123\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000424\n",
      "   MAE:  0.016755\n",
      "   RMSE: 0.020582\n",
      "\n",
      "============================================================\n",
      "Testing Classic TCN configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;66;03m#run cross-validation\u001B[39;00m\n\u001B[32m     11\u001B[39m cv = CrossValidator(\n\u001B[32m     12\u001B[39m     model_type=\u001B[33m\"\u001B[39m\u001B[33mclassic\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m     hyperparameter_grid=hyperparameter_grid,\n\u001B[32m     14\u001B[39m     num_epochs=\u001B[32m100\u001B[39m,\n\u001B[32m     15\u001B[39m     seed=\u001B[32m42\u001B[39m\n\u001B[32m     16\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_series\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_series\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m best_config_tcn = cv.get_best_config()\n\u001B[32m     19\u001B[39m results_tcn_df = cv.get_results()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/train.py:443\u001B[39m, in \u001B[36mCrossValidator.fit\u001B[39m\u001B[34m(self, train_series, val_series)\u001B[39m\n\u001B[32m    440\u001B[39m model, training_loss = \u001B[38;5;28mself\u001B[39m._train_single_config(config, train_tensor)\n\u001B[32m    442\u001B[39m \u001B[38;5;66;03m# Evaluate on validation\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m443\u001B[39m val_mse, val_mae, val_rmse = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluate_on_validation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    444\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_tensor\u001B[49m\n\u001B[32m    445\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    447\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose:\n\u001B[32m    448\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m Validation Forecasting Metrics:\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/train.py:332\u001B[39m, in \u001B[36mCrossValidator._evaluate_on_validation\u001B[39m\u001B[34m(self, model, train_tensor, val_tensor)\u001B[39m\n\u001B[32m    330\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m    331\u001B[39m     forecast_horizon = \u001B[38;5;28mlen\u001B[39m(val_tensor)\n\u001B[32m--> \u001B[39m\u001B[32m332\u001B[39m     val_predictions = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforecast_horizon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    334\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m val_predictions.dim() > \u001B[32m1\u001B[39m:\n\u001B[32m    335\u001B[39m         val_predictions = val_predictions.squeeze()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/models.py:118\u001B[39m, in \u001B[36mTimeSeriesModel.predict\u001B[39m\u001B[34m(self, x, steps)\u001B[39m\n\u001B[32m    115\u001B[39m predictions = []\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps):\n\u001B[32m--> \u001B[39m\u001B[32m118\u001B[39m     pred, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    119\u001B[39m     next_val = pred[:, -\u001B[32m1\u001B[39m:, :]\n\u001B[32m    120\u001B[39m     predictions.append(next_val)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/models.py:145\u001B[39m, in \u001B[36mClassic_TCN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    142\u001B[39m x_transposed = x.transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n\u001B[32m    144\u001B[39m \u001B[38;5;66;03m# TCN output: (batch, num_channels[-1], seq_len)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m145\u001B[39m output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtcn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_transposed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[38;5;66;03m# predictions: (batch, 1, seq_len) -> (batch, seq_len, 1)\u001B[39;00m\n\u001B[32m    148\u001B[39m predictions = \u001B[38;5;28mself\u001B[39m.linear(output).transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/models.py:92\u001B[39m, in \u001B[36mTemporalConvNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    243\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m244\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/models.py:59\u001B[39m, in \u001B[36mTemporalBlock.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m     res = x \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.downsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.downsample(x)\n\u001B[32m     61\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.relu(out + res)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    243\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m244\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/src/models.py:27\u001B[39m, in \u001B[36mChausalConv1d.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     26\u001B[39m     \u001B[38;5;66;03m# x shape: (batch, channels, seq_len)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m     \u001B[38;5;66;03m# Remove the extra padding on the right\u001B[39;00m\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x[:, :, :-\u001B[38;5;28mself\u001B[39m.padding].contiguous()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:371\u001B[39m, in \u001B[36mConv1d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    370\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m371\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/ml/ml-project/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:366\u001B[39m, in \u001B[36mConv1d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    354\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    355\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv1d(\n\u001B[32m    356\u001B[39m         F.pad(\n\u001B[32m    357\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    364\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    365\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742b68cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from weights/model_weights_classic_tcn.pth\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Only pass architecture parameters here\n",
    "    model_classic_tcn = Classic_TCN(\n",
    "        num_channels=[128, 128, 128], \n",
    "        kernel_size=[2, 2, 2], \n",
    "        dilations=[1, 2, 4],\n",
    "        dropout=0.1\n",
    "    )\n",
    "    \n",
    "    model_classic_tcn.load_state_dict(torch.load(\"weights/model_weights_classic_tcn.pth\"))\n",
    "    model_classic_tcn.eval()\n",
    "    print(f\"Loaded model weights from 'weights/model_weights_classic_tcn.pth'\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(f\"Model architecture mismatch: {e}\")\n",
    "    print(f\"Training new model...\")\n",
    "    # Training parameters go here\n",
    "    model_classic_tcn = Trainer(\n",
    "        model_type=\"classic\",\n",
    "        num_channels=[128, 128, 128],\n",
    "        kernel_size=[2, 2, 2],\n",
    "        dilations=[1, 2, 4],\n",
    "        num_epochs=100, \n",
    "        lr=0.0001\n",
    "    ).fit(y_train.values)\n",
    "    torch.save(model_classic_tcn.state_dict(), \"weights/model_weights_classic_tcn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32994f",
   "metadata": {},
   "source": [
    "# Train Hybrid AR-TCN"
   ]
  },
  {
   "cell_type": "code",
   "id": "63915fc3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-22T17:36:35.481340Z"
    }
   },
   "source": [
    "#define hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'kernel_size': [2, 3, 5],\n",
    "    'num_filters': [64, 128],\n",
    "    'num_layers': [3, 5, 7],\n",
    "    'dilation_base': [2, 4],\n",
    "    'lr': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "#cross validate additive hybrid ARMA\n",
    "cv_add = CrossValidator(\n",
    "    model_type=\"additive\",\n",
    "    ar_orders=[1, 2, 3, 4, 5],\n",
    "    ma_orders=[1, 2, 3, 4, 5],\n",
    "    hyperparameter_grid=hyperparameter_grid,\n",
    "    num_epochs=100,\n",
    "    seed=42\n",
    ")\n",
    "cv_add.fit(train_series, val_series)\n",
    "cv_add.get_best_config()\n",
    "results_add_add = cv_add.get_results()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Epoch [20/100], Training Loss: 0.017648\n",
      "Epoch [40/100], Training Loss: 0.004138\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.004780\n",
      "   MAE:  0.066753\n",
      "   RMSE: 0.069135\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.008495\n",
      "   MAE:  0.090439\n",
      "   RMSE: 0.092168\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.003854\n",
      "   MAE:  0.059429\n",
      "   RMSE: 0.062080\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Epoch [20/100], Training Loss: 0.017648\n",
      "Epoch [40/100], Training Loss: 0.004138\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.004780\n",
      "   MAE:  0.066753\n",
      "   RMSE: 0.069135\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.008495\n",
      "   MAE:  0.090439\n",
      "   RMSE: 0.092168\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.003854\n",
      "   MAE:  0.059429\n",
      "   RMSE: 0.062080\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.001114\n",
      "   MAE:  0.029367\n",
      "   RMSE: 0.033370\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.010644\n",
      "   MAE:  0.101461\n",
      "   RMSE: 0.103168\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.042319\n",
      "   MAE:  0.204820\n",
      "   RMSE: 0.205715\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.001114\n",
      "   MAE:  0.029367\n",
      "   RMSE: 0.033370\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.010644\n",
      "   MAE:  0.101461\n",
      "   RMSE: 0.103168\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.042319\n",
      "   MAE:  0.204820\n",
      "   RMSE: 0.205715\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 7, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.006831\n",
      "   MAE:  0.080627\n",
      "   RMSE: 0.082652\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 7, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000923\n",
      "   MAE:  0.026324\n",
      "   RMSE: 0.030385\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 7, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.040177\n",
      "   MAE:  0.199425\n",
      "   RMSE: 0.200443\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 7, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.006831\n",
      "   MAE:  0.080627\n",
      "   RMSE: 0.082652\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 7, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000923\n",
      "   MAE:  0.026324\n",
      "   RMSE: 0.030385\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 64, 'num_layers': 7, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.040177\n",
      "   MAE:  0.199425\n",
      "   RMSE: 0.200443\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.002422\n",
      "   MAE:  0.045847\n",
      "   RMSE: 0.049213\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000323\n",
      "   MAE:  0.014165\n",
      "   RMSE: 0.017976\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.157112\n",
      "   MAE:  0.395934\n",
      "   RMSE: 0.396373\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.002422\n",
      "   MAE:  0.045847\n",
      "   RMSE: 0.049213\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000323\n",
      "   MAE:  0.014165\n",
      "   RMSE: 0.017976\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.157112\n",
      "   MAE:  0.395934\n",
      "   RMSE: 0.396373\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.005864\n",
      "   MAE:  0.074410\n",
      "   RMSE: 0.076578\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.008611\n",
      "   MAE:  0.090991\n",
      "   RMSE: 0.092793\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.002251\n",
      "   MAE:  0.044071\n",
      "   RMSE: 0.047445\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 5, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.005864\n",
      "   MAE:  0.074410\n",
      "   RMSE: 0.076578\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 5, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.008611\n",
      "   MAE:  0.090991\n",
      "   RMSE: 0.092793\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 5, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.002251\n",
      "   MAE:  0.044071\n",
      "   RMSE: 0.047445\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 7, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.003509\n",
      "   MAE:  0.056447\n",
      "   RMSE: 0.059235\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 7, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000875\n",
      "   MAE:  0.025566\n",
      "   RMSE: 0.029572\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 7, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.011802\n",
      "   MAE:  0.107112\n",
      "   RMSE: 0.108639\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 7, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.003509\n",
      "   MAE:  0.056447\n",
      "   RMSE: 0.059235\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 7, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000875\n",
      "   MAE:  0.025566\n",
      "   RMSE: 0.029572\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 2, 'num_filters': 128, 'num_layers': 7, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.011802\n",
      "   MAE:  0.107112\n",
      "   RMSE: 0.108639\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000570\n",
      "   MAE:  0.019229\n",
      "   RMSE: 0.023875\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.001073\n",
      "   MAE:  0.028764\n",
      "   RMSE: 0.032753\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 2, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.021430\n",
      "   MAE:  0.145280\n",
      "   RMSE: 0.146391\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.0001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.000570\n",
      "   MAE:  0.019229\n",
      "   RMSE: 0.023875\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.001}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.001073\n",
      "   MAE:  0.028764\n",
      "   RMSE: 0.032753\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 3, 'dilation_base': 4, 'lr': 0.01}\n",
      "============================================================\n",
      "Early stopping after 10 epochs\n",
      "\n",
      " Validation Forecasting Metrics:\n",
      "   MSE:  0.021430\n",
      "   MAE:  0.145280\n",
      "   RMSE: 0.146391\n",
      "\n",
      "============================================================\n",
      "Testing Additive Hybrid ARMA(1,1) configuration: {'kernel_size': 3, 'num_filters': 64, 'num_layers': 5, 'dilation_base': 2, 'lr': 0.0001}\n",
      "============================================================\n",
      "Epoch [20/100], Training Loss: 0.008203\n",
      "Early stopping after 10 epochs\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1431b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from weights/model_weights_hybrid_ar1.pth\n",
      "Loaded model weights from weights/model_weights_hybrid_ar5.pth\n"
     ]
    }
   ],
   "source": [
    "#Loop to train the AR model to be flexible\n",
    "AR_ORDERS = [1, 5]  # Train both AR(1)+TCN and AR(5)+TCN\n",
    "\n",
    "hybrid_results = {}\n",
    "\n",
    "for ar_order in AR_ORDERS:\n",
    "    try:\n",
    "        weights_path = f\"weights/model_weights_hybrid_ar{ar_order}.pth\"\n",
    "        \n",
    "        model = AdditiveHybrid_AR_TCN(ar_order=ar_order,\n",
    "                                    num_channels=[128, 128, 128], \n",
    "                                    kernel_size=[2, 2, 2], \n",
    "                                    dilations=[1, 2, 4],\n",
    "                                    dropout=0.1)\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "        model.eval()\n",
    "        print(f\"Loaded model weights from {weights_path}\")\n",
    "        # Store the model\n",
    "        hybrid_results[ar_order] = {\n",
    "                'model': model,\n",
    "            }\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Model architecture mismatch: {e}\")\n",
    "        print(f\"Training new model...\")\n",
    "        # Training parameters go here\n",
    "        model = train_additive_model(\n",
    "            y_train.values,\n",
    "            ar_order=ar_order, \n",
    "            num_channels=[128, 128, 128],\n",
    "            kernel_size=[2, 2, 2],\n",
    "            dilations=[1, 2, 4],\n",
    "            num_epochs=100, \n",
    "            lr=0.0001\n",
    "        )\n",
    "        torch.save(model.state_dict(), weights_path)\n",
    "        print(f\"Model trained and saved to {weights_path}\")\n",
    "        # Store the model\n",
    "        hybrid_results[ar_order] = {\n",
    "            'model': model\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601dfec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR prediction shape: (715,)\n",
      "Classic prediction shape: torch.Size([1, 714, 1])\n",
      "Additive prediction shape: torch.Size([1, 714, 1])\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS - True Hybrid Models)\n",
      "============================================================\n",
      "MSE AR(1):                                 0.000593\n",
      "MSE AR(5):                                 0.000593\n",
      "MSE Classic TCN:                           0.000636\n",
      "MSE Hybrid AR(1) + TCN (L + N):            0.000584\n",
      "MSE Hybrid AR(5) + TCN (L + N):            0.000584\n",
      "============================================================\n",
      "MAE AR(1):                                 0.018579\n",
      "MAE AR(5):                                 0.018581\n",
      "MAE Classic TCN:                           0.019639\n",
      "MAE Hybrid AR(1) + TCN (L + N):            0.018366\n",
      "MAE Hybrid AR(5) + TCN (L + N):            0.018366\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Extract models\n",
    "model_hybrid_ar1 = hybrid_results[1][\"model\"]\n",
    "model_hybrid_ar5 = hybrid_results[5][\"model\"]\n",
    "model_ar1 = ar_results[1][\"model\"]\n",
    "model_ar5 = ar_results[5][\"model\"]\n",
    "\n",
    "# Evaluate models\n",
    "model_classic_tcn.eval()\n",
    "model_hybrid_ar1.eval()\n",
    "model_hybrid_ar5.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "\n",
    "    predictions_class, targets_class = model_classic_tcn(y_train_tensor)\n",
    "    predictions_add1, targets_add1 = model_hybrid_ar1(y_train_tensor)\n",
    "    predictions_add5, targets_add5 = model_hybrid_ar5(y_train_tensor)\n",
    "\n",
    "    print(f\"AR prediction shape: {pred_vals.shape}\")\n",
    "    print(f\"Classic prediction shape: {predictions_class.shape}\")\n",
    "    print(f\"Additive prediction shape: {predictions_add1.shape}\")\n",
    "\n",
    "# Calculate MSE\n",
    "y_train_adj = y_train.values[1:]  # Adjust for the shift in predictions\n",
    "predictions_class_np = predictions_class.numpy().flatten()\n",
    "predictions_add1_np = predictions_add1.numpy().flatten()\n",
    "predictions_add5_np = predictions_add1.numpy().flatten()\n",
    "\n",
    "mse_class = np.mean((y_train_adj - predictions_class_np) ** 2)\n",
    "mse_hybrid_add1 = np.mean((y_train_adj - predictions_add1_np) ** 2)\n",
    "mse_hybrid_add5 = np.mean((y_train_adj - predictions_add5_np) ** 2)\n",
    "\n",
    "mae_class = np.mean(np.absolute(y_train_adj - predictions_class_np))\n",
    "mae_hybrid_add1 = np.mean(np.absolute(y_train_adj - predictions_add1_np))\n",
    "mae_hybrid_add5 = np.mean(np.absolute(y_train_adj - predictions_add5_np))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESULTS - True Hybrid Models)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MSE AR(1):                                 {ar_results[1][\"mse\"]:.6f}\")\n",
    "print(f\"MSE AR(5):                                 {ar_results[5][\"mse\"]:.6f}\")\n",
    "print(f\"MSE Classic TCN:                           {mse_class:.6f}\")\n",
    "print(f\"MSE Hybrid AR(1) + TCN (L + N):            {mse_hybrid_add1:.6f}\")\n",
    "print(f\"MSE Hybrid AR(5) + TCN (L + N):            {mse_hybrid_add5:.6f}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAE AR(1):                                 {ar_results[1][\"mae\"]:.6f}\")\n",
    "print(f\"MAE AR(5):                                 {ar_results[5][\"mae\"]:.6f}\")\n",
    "print(f\"MAE Classic TCN:                           {mae_class:.6f}\")\n",
    "print(f\"MAE Hybrid AR(1) + TCN (L + N):            {mae_hybrid_add1:.6f}\")\n",
    "print(f\"MAE Hybrid AR(5) + TCN (L + N):            {mae_hybrid_add5:.6f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd23565",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27fcd5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on combined training and validation sets\n",
    "train_val_combined = concatenate([train_series, val_series], axis=0, ignore_time_axis=True)\n",
    "train_val_tensor = torch.FloatTensor(train_val_combined.values().flatten())\n",
    "test_tensor = torch.FloatTensor(test_series.values().flatten())\n",
    "\n",
    "return_series = TimeSeries.from_values(returns)\n",
    "test_series_aligned = return_series[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8c53f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_ORDERS = [1, 5]\n",
    "forecast_horizon = [1, 2, 3, 5, 10, 30, 50, 100, 150, 200]\n",
    "results_mse_df = pd.DataFrame(columns=[f\"{time}-step MSE\" for time in forecast_horizon])\n",
    "results_mae_df = pd.DataFrame(columns=[f\"{time}-step MAE\" for time in forecast_horizon])\n",
    "\n",
    "# Retrain the models on training set + validation set\n",
    "model_ar1_final = ARIMA(p=1, d=0, q=0)\n",
    "model_ar1_final.fit(train_val_combined)\n",
    "model_ar5_final = ARIMA(p=5, d=0, q=0)\n",
    "model_ar5_final.fit(train_val_combined)\n",
    "\n",
    "\n",
    "\n",
    "for ar in AR_ORDERS:\n",
    "    model = globals()[f\"model_ar{ar}_final\"]\n",
    "    for time in forecast_horizon:\n",
    "        forecast_series = model.historical_forecasts(\n",
    "            series=return_series,\n",
    "            start=val_end,\n",
    "            forecast_horizon=time,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            last_points_only=True\n",
    "        )\n",
    "        \n",
    "        # Compute metrics against the actual test series\n",
    "        results_mse_df.loc[f\"AR({ar})\", f\"{time}-step MSE\"] = MSE(test_series_aligned, forecast_series, intersect=True)\n",
    "        results_mae_df.loc[f\"AR({ar})\", f\"{time}-step MAE\"] = MAE(test_series_aligned, forecast_series, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0180ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic TCN - Epoch [10/100], Loss: 0.005302\n",
      "Classic TCN - Epoch [20/100], Loss: 0.004864\n",
      "Classic TCN - Epoch [30/100], Loss: 0.004295\n",
      "Classic TCN - Epoch [40/100], Loss: 0.002263\n",
      "Classic TCN - Epoch [50/100], Loss: 0.002272\n",
      "Classic TCN - Epoch [60/100], Loss: 0.002069\n",
      "Classic TCN - Epoch [70/100], Loss: 0.002209\n",
      "Classic TCN - Epoch [80/100], Loss: 0.001989\n",
      "Classic TCN - Epoch [90/100], Loss: 0.001906\n",
      "Classic TCN - Epoch [100/100], Loss: 0.001980\n"
     ]
    }
   ],
   "source": [
    "# Specify optimal TCN model based on cross-validation and train it on train+val set\n",
    "model_classic_tcn_final = train_tcn_model(train_val_combined, \n",
    "                                            num_channels=[128, 128, 128],\n",
    "                                            kernel_size=[2, 2, 2],\n",
    "                                            dilations=[1, 2, 4],\n",
    "                                            num_epochs=100, \n",
    "                                            lr=0.0001)\n",
    "\n",
    "model_classic_tcn_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_classic_tcn_final), \n",
    "    lags=125 # Choose effective lag memory fore recursive forecasting\n",
    ")\n",
    "model_classic_tcn_darts.fit(train_series) \n",
    "\n",
    "for time in forecast_horizon:\n",
    "        forecast_series = model_classic_tcn_darts.historical_forecasts(\n",
    "            series=return_series,\n",
    "            start=val_end,\n",
    "            forecast_horizon=time,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            overlap_end=True,\n",
    "            last_points_only=True\n",
    "        )\n",
    "        \n",
    "        # Compute metrics against the actual test series\n",
    "        results_mse_df.loc[\"Classic TCN\", f\"{time}-step MSE\"] = MSE(test_series_aligned, forecast_series, intersect=True)\n",
    "        results_mae_df.loc[\"Classic TCN\", f\"{time}-step MAE\"] = MAE(test_series_aligned, forecast_series, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1452cf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Hybrid AR(1) + TCN - Epoch [10/100], Loss: 0.005729\n",
      "Additive Hybrid AR(1) + TCN - Epoch [20/100], Loss: 0.002379\n",
      "Additive Hybrid AR(1) + TCN - Epoch [30/100], Loss: 0.001509\n",
      "Additive Hybrid AR(1) + TCN - Epoch [40/100], Loss: 0.001476\n",
      "Additive Hybrid AR(1) + TCN - Epoch [50/100], Loss: 0.001166\n",
      "Additive Hybrid AR(1) + TCN - Epoch [60/100], Loss: 0.001180\n",
      "Additive Hybrid AR(1) + TCN - Epoch [70/100], Loss: 0.001051\n",
      "Additive Hybrid AR(1) + TCN - Epoch [80/100], Loss: 0.000985\n",
      "Additive Hybrid AR(1) + TCN - Epoch [90/100], Loss: 0.000958\n",
      "Additive Hybrid AR(1) + TCN - Epoch [100/100], Loss: 0.000883\n",
      "Additive Hybrid AR(1) + TCN - Epoch [10/100], Loss: 0.005300\n",
      "Additive Hybrid AR(1) + TCN - Epoch [20/100], Loss: 0.004681\n",
      "Additive Hybrid AR(1) + TCN - Epoch [30/100], Loss: 0.004430\n",
      "Additive Hybrid AR(1) + TCN - Epoch [40/100], Loss: 0.002213\n",
      "Additive Hybrid AR(1) + TCN - Epoch [50/100], Loss: 0.002440\n",
      "Additive Hybrid AR(1) + TCN - Epoch [60/100], Loss: 0.002236\n",
      "Additive Hybrid AR(1) + TCN - Epoch [70/100], Loss: 0.002229\n",
      "Additive Hybrid AR(1) + TCN - Epoch [80/100], Loss: 0.002270\n",
      "Additive Hybrid AR(1) + TCN - Epoch [90/100], Loss: 0.001967\n",
      "Additive Hybrid AR(1) + TCN - Epoch [100/100], Loss: 0.001818\n"
     ]
    }
   ],
   "source": [
    "# Specify optimal hybrid models based on cross-validation and train it on train+val set\n",
    "model_hybrid_ar1_final = train_additive_model(train_val_combined, \n",
    "                                            num_channels=[64]*7,\n",
    "                                            kernel_size=[3]*7,\n",
    "                                            dilations=[1, 2, 4, 8, 16, 32, 64],\n",
    "                                            num_epochs=100, \n",
    "                                            lr=0.001)\n",
    "model_hybrid_ar5_final = train_additive_model(train_val_tensor, \n",
    "                                            num_channels=[128, 128, 128],\n",
    "                                            kernel_size=[2, 2, 2],\n",
    "                                            dilations=[1, 2, 4],\n",
    "                                            num_epochs=100, \n",
    "                                            lr=0.0001)\n",
    "\n",
    "model_hybrid_ar1_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_hybrid_ar1_final), \n",
    "    lags=128 \n",
    ")\n",
    "\n",
    "model_hybrid_ar5_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_hybrid_ar5_final), \n",
    "    lags=128\n",
    ")\n",
    "\n",
    "model_hybrid_ar1_darts.fit(train_series) \n",
    "model_hybrid_ar5_darts.fit(train_series)\n",
    "\n",
    "for ar in AR_ORDERS:\n",
    "    model = globals()[f\"model_hybrid_ar{ar}_darts\"]\n",
    "    for time in forecast_horizon:\n",
    "        forecast_series = model.historical_forecasts(\n",
    "            series=return_series,\n",
    "            start=val_end,\n",
    "            forecast_horizon=time,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            overlap_end=True,\n",
    "            last_points_only=True\n",
    "        )\n",
    "\n",
    "        # Compute metrics against the actual test series\n",
    "        results_mse_df.loc[f\"AR({ar})+TCN\", f\"{time}-step MSE\"] = MSE(test_series_aligned, forecast_series, intersect=True)\n",
    "        results_mae_df.loc[f\"AR({ar})+TCN\", f\"{time}-step MAE\"] = MAE(test_series_aligned, forecast_series, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10e507f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-step MSE</th>\n",
       "      <th>2-step MSE</th>\n",
       "      <th>3-step MSE</th>\n",
       "      <th>5-step MSE</th>\n",
       "      <th>10-step MSE</th>\n",
       "      <th>30-step MSE</th>\n",
       "      <th>50-step MSE</th>\n",
       "      <th>100-step MSE</th>\n",
       "      <th>150-step MSE</th>\n",
       "      <th>200-step MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR(1)</th>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR(5)</th>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic TCN</th>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR(1)+TCN</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR(5)+TCN</th>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1-step MSE 2-step MSE 3-step MSE 5-step MSE 10-step MSE  \\\n",
       "AR(1)         0.000376   0.000378   0.000379   0.000382    0.000384   \n",
       "AR(5)         0.000388   0.000389   0.000384   0.000384    0.000384   \n",
       "Classic TCN   0.000365   0.000366   0.000369   0.000378    0.000382   \n",
       "AR(1)+TCN     0.000415   0.000415   0.000409   0.000408    0.000409   \n",
       "AR(5)+TCN     0.000369    0.00037    0.00037   0.000378    0.000382   \n",
       "\n",
       "            30-step MSE 50-step MSE 100-step MSE 150-step MSE 200-step MSE  \n",
       "AR(1)          0.000399    0.000416     0.000369     0.000227     0.000155  \n",
       "AR(5)          0.000399    0.000416     0.000369     0.000227     0.000155  \n",
       "Classic TCN    0.000397    0.000415     0.000368     0.000225     0.000156  \n",
       "AR(1)+TCN      0.000429    0.000452     0.000402     0.000253     0.000196  \n",
       "AR(5)+TCN      0.000397    0.000415     0.000369     0.000225     0.000157  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae1ac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-step MAE</th>\n",
       "      <th>2-step MAE</th>\n",
       "      <th>3-step MAE</th>\n",
       "      <th>5-step MAE</th>\n",
       "      <th>10-step MAE</th>\n",
       "      <th>30-step MAE</th>\n",
       "      <th>50-step MAE</th>\n",
       "      <th>100-step MAE</th>\n",
       "      <th>150-step MAE</th>\n",
       "      <th>200-step MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR(1)</th>\n",
       "      <td>0.014347</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.010151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR(5)</th>\n",
       "      <td>0.01454</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.01442</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.010152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic TCN</th>\n",
       "      <td>0.014226</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>0.014417</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.01196</td>\n",
       "      <td>0.010308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR(1)+TCN</th>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.01524</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>0.01595</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.011954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR(5)+TCN</th>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.01441</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.014949</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.010397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1-step MAE 2-step MAE 3-step MAE 5-step MAE 10-step MAE  \\\n",
       "AR(1)         0.014347   0.014346   0.014383   0.014421    0.014411   \n",
       "AR(5)          0.01454   0.014531   0.014472   0.014503     0.01442   \n",
       "Classic TCN   0.014226   0.014236   0.014281   0.014374    0.014417   \n",
       "AR(1)+TCN     0.015445   0.015429    0.01524   0.015219    0.015235   \n",
       "AR(5)+TCN     0.014295   0.014303   0.014311    0.01441    0.014443   \n",
       "\n",
       "            30-step MAE 50-step MAE 100-step MAE 150-step MAE 200-step MAE  \n",
       "AR(1)          0.014606    0.014875     0.013947     0.011883     0.010151  \n",
       "AR(5)          0.014605    0.014875     0.013947     0.011883     0.010152  \n",
       "Classic TCN    0.014634    0.014908     0.013995      0.01196     0.010308  \n",
       "AR(1)+TCN      0.015642     0.01595     0.014896     0.013094     0.011954  \n",
       "AR(5)+TCN      0.014672    0.014949     0.014035     0.012022     0.010397  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mae_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
