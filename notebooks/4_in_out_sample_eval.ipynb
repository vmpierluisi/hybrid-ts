{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change to the project root directory\n",
    "project_root = pathlib.Path().resolve().parent\n",
    "os.chdir(project_root)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.models import ARIMA\n",
    "from darts import TimeSeries\n",
    "from darts import concatenate\n",
    "from darts.metrics import mse as MSE\n",
    "from darts.metrics import mae as MAE\n",
    "from darts.models import SKLearnModel\n",
    "import torch\n",
    "from src.train import Trainer\n",
    "from src.train import DartsBridge\n",
    "from src.models import Classic_TCN\n",
    "from src.models import AdditiveHybrid_ARMA_TCN\n",
    "from src.diagnose import compute_erf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path(\"data/DCOILWTICO.csv\")\n",
    "print(f\"Loading from: {data_path.absolute()}\")\n",
    "print(f\"File exists: {data_path.exists()}\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "data.rename(columns = {\"observation_date\" : \"date\", \"DCOILWTICO\" : \"price\"}, inplace  = True)\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data = data.set_index(\"date\")\n",
    "data[\"return\"] = np.log(data[\"price\"]) - np.log(data[\"price\"].shift(1))\n",
    "returns = data[\"return\"].replace([np.inf, -np.inf], np.nan).dropna().astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three-way split: 60% train, 20% validation, 20% test\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_end = int(len(returns) * train_ratio)\n",
    "val_end = int(len(returns) * (train_ratio + val_ratio))\n",
    "\n",
    "# Split the data\n",
    "y_train = returns.iloc[:train_end]\n",
    "y_val = returns.iloc[train_end:val_end]\n",
    "y_test = returns.iloc[val_end:]\n",
    "\n",
    "# Convert to darts TimeSeries objects\n",
    "train_series = TimeSeries.from_values(y_train)\n",
    "val_series = TimeSeries.from_values(y_val)\n",
    "test_series = TimeSeries.from_values(y_test)\n",
    "\n",
    "print(f\"Train size: {len(train_series)} ({train_ratio*100}%)\")\n",
    "print(f\"Validation size: {len(val_series)} ({val_ratio*100}%)\")\n",
    "print(f\"Test size: {len(test_series)} ({(1-train_ratio-val_ratio)*100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Train AR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_ORDERS = [1, 5]\n",
    "ar_model = {}\n",
    "for ar_order in AR_ORDERS:\n",
    "    try:\n",
    "        ar_model[ar_order] = ARIMA.load(f\"weights/model_weights_ar{ar_order}.pkl\")\n",
    "        print(f\"Loaded model weights from weights/model_weights_ar{ar_order}.pkl\")\n",
    "        print(f\"Model accessible under: model_ar{[ar_order]}\")\n",
    "    except (RuntimeError, FileNotFoundError) as e:\n",
    "        ar_model[ar_order] = ARIMA(p=ar_order, d=0, q=0)\n",
    "        ar_model[ar_order].fit(train_series)\n",
    "        ar_model[ar_order].save(f'weights/model_weights_ar{ar_order}.pkl')\n",
    "        print(f\"Model accessible under: model_ar{ar_order}.pkl\")\n",
    "\n",
    "model_ar1 = ar_model[1]\n",
    "model_ar5 = ar_model[5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Train TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Only pass architecture parameters here\n",
    "    model_classic_tcn = Classic_TCN(\n",
    "        num_channels=[128, 128, 128], \n",
    "        kernel_size=[2, 2, 2], \n",
    "        dilations=[1, 2, 4],\n",
    "        dropout=0.1\n",
    "    )\n",
    "    \n",
    "    model_classic_tcn.load_state_dict(torch.load(\"weights/model_weights_classic_tcn.pth\"))\n",
    "    model_classic_tcn.eval()\n",
    "    print(f\"Loaded model weights from 'weights/model_weights_classic_tcn.pth'\")\n",
    "\n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    print(f\"Model architecture mismatch: {e}\")\n",
    "    print(f\"Training new model...\")\n",
    "    # Training parameters go here\n",
    "    model_classic_tcn = Trainer(\n",
    "        model_type=\"classic\",\n",
    "        num_channels=[128, 128, 128],\n",
    "        kernel_size=[2, 2, 2],\n",
    "        dilations=[1, 2, 4],\n",
    "        num_epochs=100, \n",
    "        lr=0.0001\n",
    "    ).fit(y_train.values)\n",
    "    torch.save(model_classic_tcn.state_dict(), \"weights/model_weights_classic_tcn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Train Hybrid ARMA-TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Only pass architecture parameters here\n",
    "    model_hybrid_arma = AdditiveHybrid_ARMA_TCN(\n",
    "        ar_order=1,\n",
    "        ma_order=0,\n",
    "        num_channels=[64]*7,\n",
    "        kernel_size=[3]*7,\n",
    "        dilations=[1, 2, 4, 8, 16, 32, 64],\n",
    "        dropout=0.1\n",
    "\n",
    "    )\n",
    "\n",
    "    model_hybrid_arma.load_state_dict(torch.load(\"weights/model_weights_hybrid_arma.pth\"))\n",
    "    model_hybrid_arma.eval()\n",
    "    print(f\"Loaded model weights from 'weights/model_weights_hybrid_arma.pth'\")\n",
    "\n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    print(f\"Model architecture mismatch: {e}\")\n",
    "    print(f\"Training new model...\")\n",
    "    # Training parameters go here\n",
    "    model_hybrid_arma = Trainer(\n",
    "        model_type=\"additive\",\n",
    "        ar_order=1,\n",
    "        ma_order=0,\n",
    "        num_channels=[64]*7,\n",
    "        kernel_size=[3]*7,\n",
    "        dilations=[1, 2, 4, 8, 16, 32, 64],\n",
    "        num_epochs=100,\n",
    "        lr=0.001\n",
    "    ).fit(y_train.values)\n",
    "    model_hybrid_arma = model_hybrid_arma.get_model()\n",
    "    torch.save(model_hybrid_arma.state_dict(), \"weights/model_weights_hybrid_arma.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Effective Receptive Field Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_tcn = compute_erf(model_classic_tcn, sequence_length=100, device='mps')\n",
    "sensitivity_arma = compute_erf(model_hybrid_arma, sequence_length=200, device='mps')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=False, figsize=(12, 10))\n",
    "\n",
    "ax1.plot(sensitivity_tcn, color='#2E86AB')\n",
    "ax1.axvline(x=50-15, linestyle='--', color='#A23B72')\n",
    "ax1.text(x=31, y=0.1, s=\"ERF=15\", color='#A23B72', fontsize=12)\n",
    "ax1.set_ylabel('|gradient|', fontsize=12)\n",
    "ax1.set_title('Classic TCN - Empirical Receptive Field', fontsize=14)\n",
    "ax1.grid(alpha=0.3, linestyle=':', linewidth=0.5)\n",
    "\n",
    "ax2.plot(sensitivity_arma, color='#2E86AB')\n",
    "ax2.axvline(x=200-130, linestyle='--', color='#A23B72')\n",
    "ax2.text(x=52, y=0.4, s=\"ERF=130\", color='#A23B72', fontsize=12)\n",
    "ax2.set_xlabel('Input timestep (0 = oldest)', fontsize=12)\n",
    "ax2.set_ylabel('|gradient|', fontsize=12)\n",
    "ax2.set_title('ARMA+TCN - Empirical Receptive Field', fontsize=14)\n",
    "ax2.grid(alpha=0.3, linestyle=':', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# In-Sample Forecast Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on combined training and validation sets\n",
    "train_val_combined = concatenate([train_series, val_series], axis=0, ignore_time_axis=True)\n",
    "return_series = TimeSeries.from_values(returns)\n",
    "val_series_aligned = return_series[:val_end]\n",
    "\n",
    "# In-Sample Forecast Evaluation (1-step, simple forecasting)\n",
    "results_insample_mse_df = pd.DataFrame(columns=[\"1-step MSE\"])\n",
    "results_insample_mae_df = pd.DataFrame(columns=[\"1-step MAE\"])\n",
    "\n",
    "# AR models: use historical_forecasts on train_series\n",
    "for ar in AR_ORDERS:\n",
    "    model = ar_model[ar]\n",
    "    forecast_series = model.historical_forecasts(\n",
    "        series=train_val_combined,\n",
    "        start=train_end,\n",
    "        forecast_horizon=1,\n",
    "        stride=1,\n",
    "        retrain=False,\n",
    "        last_points_only=True\n",
    "    )\n",
    "    results_insample_mse_df.loc[f\"AR({ar})\", \"1-step MSE\"] = MSE(val_series_aligned, forecast_series, intersect=True)\n",
    "    results_insample_mae_df.loc[f\"AR({ar})\", \"1-step MAE\"] = MAE(val_series_aligned, forecast_series, intersect=True)\n",
    "\n",
    "# Classic TCN: wrap in DartsBridge for 1-step simple forecasting\n",
    "model_classic_tcn_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_classic_tcn),\n",
    "    lags=15 # From the ERP diagnosis\n",
    ")\n",
    "model_classic_tcn_darts.fit(train_series)\n",
    "\n",
    "forecast_series = model_classic_tcn_darts.historical_forecasts(\n",
    "    series=train_val_combined,\n",
    "    start=train_end,\n",
    "    forecast_horizon=1,\n",
    "    stride=1,\n",
    "    retrain=False,\n",
    "    last_points_only=True\n",
    ")\n",
    "results_insample_mse_df.loc[\"Classic TCN\", \"1-step MSE\"] = MSE(val_series_aligned, forecast_series, intersect=True)\n",
    "results_insample_mae_df.loc[\"Classic TCN\", \"1-step MAE\"] = MAE(val_series_aligned, forecast_series, intersect=True)\n",
    "\n",
    "# Hybrid ARMA+TCN: wrap in DartsBridge for 1-step simple forecasting\n",
    "model_hybrid_arma_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_hybrid_arma),\n",
    "    lags=130 # From the ERP diagnosis\n",
    ")\n",
    "model_hybrid_arma_darts.fit(train_series)\n",
    "\n",
    "forecast_series = model_hybrid_arma_darts.historical_forecasts(\n",
    "    series=train_val_combined,\n",
    "    start=train_end,\n",
    "    forecast_horizon=1,\n",
    "    stride=1,\n",
    "    retrain=False,\n",
    "    last_points_only=True\n",
    ")\n",
    "results_insample_mse_df.loc[\"ARMA+TCN\", \"1-step MSE\"] = MSE(val_series_aligned, forecast_series, intersect=True)\n",
    "results_insample_mae_df.loc[\"ARMA+TCN\", \"1-step MAE\"] = MAE(val_series_aligned, forecast_series, intersect=True)\n",
    "\n",
    "print(results_insample_mse_df)\n",
    "print()\n",
    "print(results_insample_mae_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Out-of-Sample Forecast Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on combined training and validation sets\n",
    "train_val_combined = concatenate([train_series, val_series], axis=0, ignore_time_axis=True)\n",
    "test_series_aligned = return_series[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define out-of-sample horizon for testing\n",
    "forecast_horizon = [1, 2, 3, 5, 10, 30, 50, 100, 150, 200]\n",
    "results_mse_df = pd.DataFrame(columns=[f\"{time}-step MSE\" for time in forecast_horizon])\n",
    "results_mae_df = pd.DataFrame(columns=[f\"{time}-step MAE\" for time in forecast_horizon])\n",
    "\n",
    "# Retrain the models on training set + validation set\n",
    "model_ar1_final = ARIMA(p=1, d=0, q=0)\n",
    "model_ar1_final.fit(train_val_combined)\n",
    "model_ar5_final = ARIMA(p=5, d=0, q=0)\n",
    "model_ar5_final.fit(train_val_combined)\n",
    "\n",
    "\n",
    "for ar in AR_ORDERS:\n",
    "    model = globals()[f\"model_ar{ar}_final\"]\n",
    "    for time in forecast_horizon:\n",
    "        forecast_series = model.historical_forecasts(\n",
    "            series=return_series,\n",
    "            start=val_end,\n",
    "            forecast_horizon=time,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            last_points_only=True\n",
    "        )\n",
    "        \n",
    "        # Compute metrics against the actual test series\n",
    "        results_mse_df.loc[f\"AR({ar})\", f\"{time}-step MSE\"] = MSE(test_series_aligned, forecast_series, intersect=True)\n",
    "        results_mae_df.loc[f\"AR({ar})\", f\"{time}-step MAE\"] = MAE(test_series_aligned, forecast_series, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify optimal TCN model based on cross-validation and train it on train+val set\n",
    "model_classic_tcn_final = Trainer(model_type=\"classic\",\n",
    "                                  num_channels=[128]*3,\n",
    "                                  kernel_size=[2]*3,\n",
    "                                  dilations=[1, 2, 4],\n",
    "                                  num_epochs=5000,\n",
    "                                  patience=100,\n",
    "                                  lr=0.0001,\n",
    "                                  verbose=False).fit(train_val_combined).get_model()\n",
    "\n",
    "model_classic_tcn_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_classic_tcn_final),\n",
    "    lags=15 # Choose effective lag memory fore recursive forecasting\n",
    ")\n",
    "model_classic_tcn_darts.fit(train_val_combined)\n",
    "\n",
    "for time in forecast_horizon:\n",
    "        forecast_series = model_classic_tcn_darts.historical_forecasts(\n",
    "            series=return_series,\n",
    "            start=val_end,\n",
    "            forecast_horizon=time,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            overlap_end=True,\n",
    "            last_points_only=True\n",
    "        )\n",
    "        \n",
    "        # Compute metrics against the actual test series\n",
    "        results_mse_df.loc[\"Classic TCN\", f\"{time}-step MSE\"] = MSE(test_series_aligned, forecast_series, intersect=True)\n",
    "        results_mae_df.loc[\"Classic TCN\", f\"{time}-step MAE\"] = MAE(test_series_aligned, forecast_series, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify optimal hybrid models based on cross-validation and train it on train+val set\n",
    "model_hybrid_final = Trainer(\n",
    "        model_type=\"additive\",\n",
    "        ar_order=1,\n",
    "        ma_order=0,\n",
    "        num_channels=[64]*7,\n",
    "        kernel_size=[3]*7,\n",
    "        dilations=[1, 2, 4, 8, 16, 32, 64],\n",
    "        patience=50,\n",
    "        num_epochs=5000,\n",
    "        lr=0.001,\n",
    "        verbose=False,\n",
    "    ).fit(train_val_combined).get_model()\n",
    "\n",
    "model_hybrid_darts = SKLearnModel(\n",
    "    model=DartsBridge(model_hybrid_final),\n",
    "    lags=130\n",
    ")\n",
    "\n",
    "model_hybrid_darts.fit(train_val_combined)\n",
    "\n",
    "\n",
    "for time in forecast_horizon:\n",
    "    forecast_series = model_hybrid_darts.historical_forecasts(\n",
    "            series=return_series,\n",
    "            start=val_end,\n",
    "            forecast_horizon=time,\n",
    "            stride=1,\n",
    "            retrain=False,\n",
    "            overlap_end=True,\n",
    "            last_points_only=True\n",
    "        )\n",
    "\n",
    "        # Compute metrics against the actual test series\n",
    "    results_mse_df.loc[f\"ARMA+TCN\", f\"{time}-step MSE\"] = MSE(test_series_aligned, forecast_series, intersect=True)\n",
    "    results_mae_df.loc[f\"ARMA+TCN\", f\"{time}-step MAE\"] = MAE(test_series_aligned, forecast_series, intersect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_mse_df)\n",
    "print()\n",
    "print(results_mae_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
